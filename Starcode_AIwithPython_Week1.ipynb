{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b93f3f-2628-4719-ba03-d5d35bb9e92b",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence with Python\n",
    "\n",
    "Hi there! Welcome to the 10-week course where you will learn exciting new things all around AI Intelligence with Python. \n",
    "\n",
    "Why Python? This programming language stands out for its simple structure and high flexibility, which is why it is one of the most used programming languages, especially for beginners. Additionally, Python is considered THE benchmark in the field of Data Science and Machine Learning. It offers the largest selection of Machine and Deep Learning libraries, including Keras, TensorFlow, and PyTorch. More on these\n",
    "later in the course!\n",
    "\n",
    "In the first week, you will dive into the Hugging Face platform and MNIST database. These are super important because MNIST helps you learn how AI recognizes images (like handwritten numbers), and Hugging Face makes it easy to work with pre-made AI models and create your own cool projects!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c043b-fb99-46b2-9322-22ace9a14c9a",
   "metadata": {},
   "source": [
    "Before we get started, we need to make an installation to set up the tools and libraries, like PyTorch and Transformers, that will allow us to build and run AI models.\n",
    "\n",
    "- tensorflow\n",
    "- pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30411f14-5e6f-43fd-abfb-a9b78e0b5fdf",
   "metadata": {},
   "source": [
    "### Hugging Face\n",
    "\n",
    "Hugging Face has a plattform called the Hugging Face Hub where you can explore and share tons of AI models, datasets, and fun demo apps. You can download these models and tweak them to work with your own data using just a few lines of code. This makes it super easy to create a custom AI model without spending a lot of time or effort!\n",
    "\n",
    "Before we start, let's define what an **AI model** is. \n",
    "AI models are computer programs that learn from a lot of data to recognize patterns or make decisions on their own — no humans needed! Whether it's understanding language, recognizing images, or even playing games, these models are everywhere in our daily lives. Do you use Google Translate or Instagram's photo tagging? Then you’re already interacting with AI models! \n",
    "\n",
    "Now, back to Hugging Face. One of the best things about Hugging Face is that it gives you access to thousands of pre-trained models that can perform various tasks on different types of data. Whether you are working with text, vision, audio, or a combination of them, you can find a model that suits your needs.\n",
    "\n",
    "Hugging Face has two main libraries that provide access to pre-trained models: **Transformers and Diffusers**. The Transformers library handles text-based tasks, such as translation, summarization, and text generation. Diffusers can handle image-based tasks, such as image synthesis, image editing, and image captioning.\n",
    "\n",
    "Now, let's check out the GPT-2 model on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116f942-23b7-4ce5-8c7d-99ef3718a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada0ec26-4b33-4e67-8205-e757b8a234e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Hello, I am learning about Artificial Intelligence with Python, vernacular language, and the language is going to have some surprises with it (I think'}, {'generated_text': 'Hello, I am learning about Artificial Intelligence with Python, irc.santa, and Python.'}, {'generated_text': 'Hello, I am learning about Artificial Intelligence with Python, ichthyism, the C++ programming language, and is currently at the very core of'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2', pad_token_id=50256)\n",
    "result = generator(\"Hello, I am learning about Artificial Intelligence with Python, \", max_length=30, num_return_sequences=3, truncation=True)\n",
    "\n",
    "print(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8230c31-3859-4cc0-95f2-2a3f4254ed13",
   "metadata": {},
   "source": [
    "> Let's quickly break down the components.\n",
    "> - The **pipeline()** function links a model with all the steps it needs to process and understand text, so you can just input your text and get a clear answer back.\n",
    "> - \"Hello, I am learning about Artificial Intelligence with Python,\": This is the **starting prompt**. GPT-2 will take this text as the beginning and try to generate the continuation of it.\n",
    "> - **max_length** =30: This specifies that the generated text should have a maximum of 30 tokens (words or pieces of words). You can adjust this number to control the length of the output.\n",
    "> - **num_return_sequences** =5: This specifies that the model should generate 5 different sequences (varied completions) for the given prompt. You can change this number to get more or fewer completions.\n",
    "\n",
    "Now it is your turn! Try generating sentences on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b0a27-88e4-4a8e-a592-8dd3d17f04df",
   "metadata": {},
   "source": [
    "Task 1.1. Use the AI model GPT-2 to generate five unique sentences. Start with any prompt you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7c85b-f6aa-4b86-bd7d-c8215f0fca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bed517-829e-4df3-af65-bfbfed837b1d",
   "metadata": {},
   "source": [
    "With GPT-2 we have generated text. Now we will try something new with the AI model BERT and dive into **text classification**. Text classification is useful to group text into fitting categories. Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40082439-93c0-4c40-a24e-7b4902077ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5017480254173279}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased')\n",
    "\n",
    "text = \"I love learning about artificial intelligence!\"\n",
    "result = classifier(text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac27edc-c1dd-453e-a30d-32a812c435da",
   "metadata": {},
   "source": [
    "Task 1.2. How do you think the model answers? Try it out with your own texts and see what it comes up with. Don't stress about the score – we'll dive deeper into this in week 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb345d6-ac41-48b4-8eae-b8c6a4a13d95",
   "metadata": {},
   "source": [
    "Let's look at another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e235e077-b99d-4892-88c2-1ea6771e86a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686883df725e4c058b399faf9a979447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93ae40c7e2e44ce801f6a152f3d0f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79152bb5506c40afb72b3bc87154a0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413465ed2bd04017ad97b9a8d95001e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa3866a88b1461b92cbbca2d4ba7acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019487ba7070456bb22f7371d760120b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This course is about AI with Python.', 'labels': ['education', 'nature', 'politics'], 'scores': [0.6706570386886597, 0.18461932241916656, 0.14472360908985138]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification', model=\"facebook/bart-large-mnli\")\n",
    "result = classifier(\"This course is about AI with Python.\",\n",
    "                   candidate_labels = [\"education\", \"books\", \"politics\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918f492-23c1-4f30-b338-9c1a1d4ca08d",
   "metadata": {},
   "source": [
    "Task 1.3. What happens here? What does the printed result tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85f0d3-76be-43ce-bb38-c265fad3cf83",
   "metadata": {},
   "source": [
    "### Neural Networks (MNIST)\n",
    "\n",
    "We’ve explored how Hugging Face provides access to various databases. Now, let’s dive into a specific and widely used one: MNIST. It’s a perfect starting point to understand how AI works with images!\n",
    "\n",
    "The **MNIST** (Modified National Institute of Standards and Technology database) is a database full of handwritten digits. Every digit is saved as a 28 × 28 pixel grayscale image and consists of 60.000 examples in the training dataset and 10,000 examples in the test dataset. These datasets work together to teach the AI and then test if it learned properly. Wow! First, we have to break down what this exactly means: \n",
    "\n",
    "> - Databases are large tables that store data in an organized way. They can be accessed by computers or applications to retrieve, add, update, or delete information.\n",
    "> - The training dataset is a set that the model learns from to recognize patterns, like how the '3' is shaped for example.\n",
    "> - Does our AI model actually work? We use the test dataset to check how well it performs on new, unseen data. This tells us whether the model has really learned or if it’s just memorizing the training data.\n",
    "\n",
    "So far, so good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546cbe2-2fd6-4bae-834f-779c8040070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aufgabe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56269fe5-0e39-4637-a1ab-d87d2c8c188d",
   "metadata": {},
   "source": [
    "MNIST consists of thousands of images of handwritten digits. For humans, recognizing these digits is easy, but for a computer, it’s a very hard challenge. Computers need a method to figure out what’s in the image.\n",
    "\n",
    "This is where neural networks come in. They are designed to recognize patterns in data — whether it’s handwritten digits in MNIST, faces in photos, or even words in sentences. Neural networks mimic the way our brains work: they learn by looking at lots of examples and finding patterns on their own. Let's take a look!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da94f4d-fe0c-4b13-b69c-bd616ff0335e",
   "metadata": {},
   "source": [
    "Neurons are brain cells that receive signals, processes them and passes it on. Artificial neurons have a similar structure. \n",
    "<<mehr Erklärung zu artifical neurons>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5bbe9-b78a-491a-89e1-3a1d8feed8b3",
   "metadata": {},
   "source": [
    "Let's practice our new knowledge with the MNIST data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
